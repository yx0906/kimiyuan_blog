# Deep Learning





ReLU:  Rectified Linear Unit



The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set.



Boltzman Machine



sigmoid function



derietive of sigmoid function: y(1-y)   



If mini-batch size =m, Batch Gradient descent

If mini-batch size =1,  Stochastic Gradient descent



If small data set: Use Batch Gradient descent 

Typical mini-batch sizes: 64, 128, 256, 512, make sure min-batch fit in CPU/GPU